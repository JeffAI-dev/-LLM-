## 多轮LLM对话如何保持记忆：上下文拼接的具体实施方法

大型语言模型（LLM）本身是无状态的，这意味着每次调用模型时，它不会自动记住之前的交互。为了在多轮对话中保持“记忆”，我们需要通过上下文拼接（context splicing）的方式，将历史对话记录传入当前提示（prompt）中。下面我将从基本原理到具体实施方法逐步解释，重点介绍几种常见的实现方式。实施时，通常依赖于LLM的API（如OpenAI的Chat Completions API）或框架（如LangChain），并需要注意上下文窗口大小（例如GPT-4的上下文窗口为8192或更多token）以避免溢出。

### 1. 基本原理：为什么需要上下文拼接？
- LLM的每次推理都是基于当前输入的prompt。
- 多轮对话的“记忆”是通过将用户和助手的上一轮（或多轮）消息拼接进新prompt来实现的。
- 拼接方式：通常以列表形式组织消息，每条消息包含角色（role，如system、user、assistant）和内容（content）。
- 潜在问题：历史过长会导致token超限、成本增加或响应变慢。因此，拼接不是简单累加，还需优化。

### 2. 方法一：简单上下文拼接（适用于短会话）
这是最基础的实现：在内存中维护一个消息列表，每次对话时追加新消息，并将整个列表作为prompt传入模型。

#### 实施步骤：
1. 初始化一个空的消息列表（history），并添加系统提示（system prompt）作为第一条消息，例如："You are a helpful assistant."。
2. 用户输入时，将用户消息追加到history。
3. 调用LLM API，传入整个history作为messages参数。
4. 获取模型响应后，将响应追加到history。
5. 重复步骤2-4。

#### 示例代码（Python，使用OpenAI API）：
```python
import openai

openai.api_key = "your-api-key"

# 初始化历史
history = [{"role": "system", "content": "You are a helpful assistant."}]

def chat_with_llm(user_input):
    # 追加用户消息
    history.append({"role": "user", "content": user_input})
    
    # 调用API
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=history
    )
    
    # 获取响应
    assistant_reply = response['choices'][0]['message']['content']
    
    # 追加助手响应
    history.append({"role": "assistant", "content": assistant_reply})
    
    return assistant_reply

# 示例多轮对话
print(chat_with_llm("Hello, who are you?"))  # 第一轮
print(chat_with_llm("What's the weather like?"))  # 第二轮，模型会记住上一轮
```

#### 优点与缺点：
- 优点：简单，直接保持完整上下文。
- 缺点：历史过长时token超限（需监控token数，使用如tiktoken库计算）。

### 3. 方法二：带截断或总结的上下文拼接（适用于中长会话）
当历史超过上下文窗口时，需要截断旧消息或总结它们，以压缩上下文。

#### 实施步骤：
1. 维护history列表。
2. 在追加新消息前，检查总token长度（使用token计数器）。
3. 如果超限，从旧消息开始截断（保留最近N条），或使用另一个LLM调用总结旧历史成一条简短消息。
4. 拼接总结后的上下文。

#### 示例代码（带截断）：
```python
import tiktoken  # 用于token计数

encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
MAX_TOKENS = 4000  # 假设窗口上限

def truncate_history(history):
    total_tokens = sum(len(encoding.encode(msg['content'])) for msg in history)
    while total_tokens > MAX_TOKENS and len(history) > 1:
        removed = history.pop(1)  # 保留system，移除最早用户/助手消息
        total_tokens -= len(encoding.encode(removed['content']))
    return history

# 在chat_with_llm函数中，追加用户消息前调用truncate_history(history)
```

#### 总结变体：
- 使用LLM总结：例如，提取history[1:-1]（旧对话），调用LLM生成总结，如"Summary of previous conversation: [summary]"，替换旧消息。

#### 优点与缺点：
- 优点：防止溢出，节省成本。
- 缺点：可能丢失细节，导致模型“遗忘”早期上下文。

### 4. 方法三：外部记忆存储与检索（适用于长会话或持久化）
对于需要长期记忆的场景，使用数据库或向量存储（如Redis、Pinecone）保存历史，并通过检索（RAG，Retrieval-Augmented Generation）拼接相关上下文。

#### 实施步骤：
1. 将每轮对话存储到外部数据库（键值对或向量嵌入）。
2. 用户新输入时，查询数据库检索相关历史（基于相似度搜索）。
3. 将检索到的相关片段拼接进prompt，例如："Based on previous context: [retrieved summary]\nUser: [new input]"。
4. 更新数据库以添加新对话。

#### 示例框架（使用LangChain）：
LangChain提供Memory模块，如ConversationBufferMemory或ConversationSummaryMemory。

```python
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.llms import OpenAI

llm = OpenAI(temperature=0)
memory = ConversationBufferMemory()  # 或ConversationSummaryMemory(llm=llm) for summarization

conversation = ConversationChain(llm=llm, memory=memory)

print(conversation.predict(input="Hello, who are you?"))
print(conversation.predict(input="What's your name?"))  # 会记住上一轮
```

- 对于向量检索：使用FAISS或Pinecone嵌入历史消息，检索top-K相关片段拼接。

#### 优点与缺点：
- 优点：支持无限长历史，持久化（跨会话），高效检索。
- 缺点：需额外基础设施，增加延迟和复杂度。

### 5. 注意事项与优化
- **Token管理**：始终计算prompt token数，避免API错误。
- **Prompt工程**：在拼接时添加分隔符，如"\n\n###\n\n"，以区分消息。
- **持久化**：对于生产环境，使用数据库（如SQLite）存储用户会话历史，按用户ID加载/保存。
- **隐私与安全**：避免拼接敏感信息。
- **测试**：在多轮中验证模型是否正确引用历史（例如，问“刚才我说什么？”）。
